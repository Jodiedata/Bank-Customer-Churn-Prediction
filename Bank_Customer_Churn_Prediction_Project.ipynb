{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bank Customer Churn Prediction Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jodiedata/Bank-Customer-Churn-Prediction/blob/master/Bank_Customer_Churn_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R88Ms0MTi0Ma"
      },
      "source": [
        "# Bank Customer Churn Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WA6lL1fni0Mb"
      },
      "source": [
        "In this project, I use supervised learning models to identify customers who are likely to churn in the future. Furthermore, I will analyze top factors that influence user retention. [Dataset information](https://www.kaggle.com/adammaus/predicting-churn-for-bank-customers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bO94-bXZi0Md"
      },
      "source": [
        "## Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SIvRSRqAi0Md"
      },
      "source": [
        "\n",
        "* [Part 1: Data Exploration](#Part-1:-Data-Exploration)\n",
        "* [Part 2: Feature Preprocessing](#Part-2:-Feature-Preprocessing)\n",
        "* [Part 3: Model Training and Results Evaluation](#Part-3:-Model-Training-and-Result-Evaluation)\n",
        "* [Part 4: Feature Selection](#Part-4:-Feature-Selection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLQaAVtsr4HS",
        "colab_type": "text"
      },
      "source": [
        "#Part 0. oad packages, load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coYzmH8Xr1xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import neccessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sl\n",
        "import sklearn.preprocessing as preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.set_option('display.max_columns',None)\n",
        "pd.set_option('display.max_rows',None)\n",
        "pd.set_option('max_colwidth',100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot7ca3o6r-fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpDRkAPesRmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_df=pd.read_table('bank.data.csv',header=0,sep=',',lineterminator='\\n')\n",
        "print(churn_df.head())\n",
        "print (\"Num of rows: \" + str(churn_df.shape[0])) # row count\n",
        "print (\"Num of columns: \" + str(churn_df.shape[1])) # col count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6bG_gAPi0Me"
      },
      "source": [
        "#Part 1. Exploratory Analysis and Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ZO12Lhs78c",
        "colab_type": "text"
      },
      "source": [
        "##1.1 Exclude erroneous data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWMm3Nges0lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if churn_df.set_index('CustomerId').index.duplicated().sum()==0:\n",
        "  print('No duplicated index.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bspx2K6fi0Me"
      },
      "source": [
        "##1.2: Understand the Raw Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht5YOBdx8NLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check data info\n",
        "churn_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZASeB8_089yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the unique values for each column\n",
        "churn_df.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ec5r_Qdi0NL",
        "colab": {}
      },
      "source": [
        "# Get target variable\n",
        "y = churn_df['Exited\\r']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rzCo_GC97rGd",
        "colab": {}
      },
      "source": [
        "# check the propotion of y = 1\n",
        "print(y.sum() / y.shape * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SsAbAjhvi0Mx"
      },
      "source": [
        "##1.3:  Understand numerical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAfYFSPuc-o",
        "colab_type": "text"
      },
      "source": [
        "###1.3.1 Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t1xsBp--_0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check missing values\n",
        "churn_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1O0xZBapthT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPGphBBFumcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(churn_df.drop(columns=['CustomerId','RowNumber'],axis=1).describe(percentiles=[0.1,0.25,0.5,0.75,0.95]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFFu2AnbvQxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(churn_df==0).sum(axis=0)/churn_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIqBIpOt_COM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# understand Numerical feature\n",
        "# discrete/continuous\n",
        "# 'CreditScore', 'Age', 'Tenure', 'NumberOfProducts'\n",
        "# 'Balance', 'EstimatedSalary'\n",
        "churn_df[['CreditScore', 'Age', 'Tenure', 'NumOfProducts','Balance', 'EstimatedSalary']].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSWC_9arxlfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename columns\n",
        "churn_df.rename(columns={'Exited\\r':'Exited'},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJH_5MRHqX5",
        "colab_type": "text"
      },
      "source": [
        "###1.3.2 'Exited' feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6o4PlZbuSYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# boxplot for numerical feature\n",
        "_,axss = plt.subplots(2,3, figsize=[20,10])\n",
        "sns.boxplot(x='Exited', y ='CreditScore', data=churn_df, ax=axss[0][0])\n",
        "sns.boxplot(x='Exited', y ='Age', data=churn_df, ax=axss[0][1])\n",
        "sns.boxplot(x='Exited', y ='Tenure', data=churn_df, ax=axss[0][2])\n",
        "sns.boxplot(x='Exited', y ='NumOfProducts', data=churn_df, ax=axss[1][0])\n",
        "sns.boxplot(x='Exited', y ='Balance', data=churn_df, ax=axss[1][1])\n",
        "sns.boxplot(x='Exited', y ='EstimatedSalary', data=churn_df, ax=axss[1][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOhgk6aI8O1",
        "colab_type": "text"
      },
      "source": [
        "insights:\\\n",
        "Senior people are more likely to churn.\\\n",
        "People have more banlance are more likely to churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W57GHp0KMEXg",
        "colab_type": "text"
      },
      "source": [
        "###1.3.3 Distribution of 'Balance' and 'Estimated Salary'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ-Ea9AbMAVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(churn_df['Balance'], bins = 10, alpha = 0.4, color='r', histtype='stepfilled', label = 'Balance')\n",
        "plt.legend(loc ='upper right')\n",
        "plt.title('Historgrams of balance before data processing')\n",
        "plt.xlabel('blance')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxhozOvANrwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(churn_df['EstimatedSalary'], bins = 500, alpha = 0.4, color='b', histtype='stepfilled', label = 'EstimatedSalary')\n",
        "plt.legend(loc ='upper right')\n",
        "plt.title('Historgrams of estimated salary before data processing')\n",
        "plt.xlabel('estimated salary')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3_AxGI1H7VT",
        "colab_type": "text"
      },
      "source": [
        "###1.2.3 Correlation among numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V4jNzgyH_uA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_score = churn_df[['CreditScore', 'Age', 'Tenure', 'NumOfProducts','Balance', 'EstimatedSalary']].corr()\n",
        "\n",
        "# show heapmap of correlations\n",
        "sns.heatmap(corr_score,cmap=\"YlGnBu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzQhvQCIIN81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the actual values of correlations\n",
        "corr_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9JGOdAjIRlh",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Understand Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZX_0E6R_E7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# understand categorical feature\n",
        "# 'Geography', 'Gender'\n",
        "# 'HasCrCard', 'IsActiveMember'\n",
        "_,axss = plt.subplots(2,2, figsize=[20,10])\n",
        "sns.countplot(x='Exited', hue='Geography', data=churn_df, ax=axss[0][0])\n",
        "sns.countplot(x='Exited', hue='Gender', data=churn_df, ax=axss[0][1])\n",
        "sns.countplot(x='Exited', hue='HasCrCard', data=churn_df, ax=axss[1][0])\n",
        "sns.countplot(x='Exited', hue='IsActiveMember', data=churn_df, ax=axss[1][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYftOiGTJoDy",
        "colab_type": "text"
      },
      "source": [
        "Insights:\\\n",
        "Female are more likely to churn.\\\n",
        "Less active members are more likely to churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aFa4d6t3i0NH"
      },
      "source": [
        "# Part 2: Feature Preprocessing\n",
        "\n",
        "feature encoding, feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83pWVkcuJ9mH",
        "colab_type": "text"
      },
      "source": [
        "After very basic Exploratory Data Analysis, we have to do some data cleaning and data preprocessing.\n",
        "We need three steps to finish  this.\n",
        "First, we need to encode the categorical feature\n",
        "Second, we need to impute the missing value for both numeric and categorical feature\n",
        "Third, we need to scale out feature,which can be better for our models' performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JMTIEpY7IfPp"
      },
      "source": [
        "Read more for handling [categorical feature](https://github.com/scikit-learn-contrib/categorical-encoding), and there is an awesome package for [encoding](https://contrib.scikit-learn.org/categorical-encoding/#category-encoders)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "MrsjiqTwi0NQ",
        "colab": {}
      },
      "source": [
        "# ordinal encoding\n",
        "churn_df['Gender'] = churn_df['Gender'] == 'Female'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dx072uC1OJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding\n",
        "churn_df = pd.get_dummies(churn_df, columns=['Geography'], drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qMpX0j91IAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sfa2fQx2xXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get feature space by dropping useless feature\n",
        "to_drop = ['RowNumber','CustomerId','Surname','Exited']\n",
        "X = churn_df.drop(to_drop, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX0AEIgC3VCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q3x9ySX_i0Nd"
      },
      "source": [
        "# Part 3: Model Training and Result Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77OjmSl9i0Nf"
      },
      "source": [
        "###3.1 Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h761_UurRKAy",
        "colab_type": "text"
      },
      "source": [
        "The impact of different scaling methods on the model performance is small. In the following model training and selections, the standard scaling (sc) data is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udziPiWQ5nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data, using standardization\n",
        "# standardization (x-mean)/std\n",
        "# normalization (x-x_min)/(x_max-x_min) ->[0,1]\n",
        "\n",
        "# 1. speed up gradient descent\n",
        "# 2. same scale\n",
        "# 3. algorithm requirments\n",
        "\n",
        "# for example, use training data to train the standardscaler to get mean and std \n",
        "# apply mean and std to both training and testing data.\n",
        "# fit_transform does the training and applying, transform only does applying.\n",
        "# Because we can't use any info from test, and we need to do the same modification\n",
        "# to testing data as well as training data\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
        "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "\n",
        "\n",
        "# min-max example: (x-x_min)/(x_max-x_min)\n",
        "# [1,2,3,4,5,6] -> fit(min:1, max:6) (scalar.min = 1, scalar.max = 6) -> transform [(1-1)/(6-1),(2-1)/(6-1)..]\n",
        "# scalar.fit(train) -> min:1, max:100\n",
        "# scalar.transform(apply to x) -> apply min:1, max:100 to X_train\n",
        "# scalar.transform -> apply min:1, max:100 to X_test\n",
        "\n",
        "# scalar.fit -> mean:1, std:100\n",
        "# scalar.transform -> apply mean:1, std:100 to X_train\n",
        "# scalar.transform -> apply mean:1, std:100 to X_test\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scale_lst = ['CreditScore','Age','Tenure','NumOfProducts','Balance','EstimatedSalary']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X[scale_lst])\n",
        "X[scale_lst] = scaler.transform(X[scale_lst])\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a32Cp99OU7t",
        "colab_type": "text"
      },
      "source": [
        "###3.2 Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkVo3jV2RH2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splite data into training and testing\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Reserve 20% for testing\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, stratify = y)\n",
        "\n",
        "print('training data has ' + str(X_train.shape[0]) + ' observation with ' + str(X_train.shape[1]) + ' features')\n",
        "print('test data has ' + str(X_test.shape[0]) + ' observation with ' + str(X_test.shape[1]) + ' features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c4UTtCQTi0Nl"
      },
      "source": [
        "###3.3: Model Training and Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "EAhSxINLi0Nl",
        "colab": {}
      },
      "source": [
        "# build models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "\n",
        "# Logistic Regression\n",
        "classifier_logistic = LogisticRegression()\n",
        "\n",
        "# K Nearest Neighbors\n",
        "classifier_KNN = KNeighborsClassifier()\n",
        "\n",
        "# Random Forest\n",
        "classifier_RF = RandomForestClassifier()\n",
        "\n",
        "#SVM\n",
        "classifier_SVM = svm.SVC() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Av0IRSoBQ3pe",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "#classifier_logistic.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EiLuzUDJRBNi",
        "colab": {}
      },
      "source": [
        "# Prediction of test data\n",
        "#classifier_logistic.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjMV04mKRJ30",
        "colab": {}
      },
      "source": [
        "# Accuracy of test data\n",
        "#classifier_logistic.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1OCgNSNri0Nn",
        "colab": {}
      },
      "source": [
        "# Use 5-fold Cross Validation to get the accuracy for different models\n",
        "model_names = ['Logistic Regression','KNN','Random Forest','SVM']\n",
        "model_list = [classifier_logistic, classifier_KNN, classifier_RF, classifier_SVM]\n",
        "count = 0\n",
        "\n",
        "for classifier in model_list:\n",
        "  if count<=len(model_list):\n",
        "    cv_score = model_selection.cross_val_score(classifier, X_train, y_train, cv=5)\n",
        "    print(cv_score)\n",
        "    print('Model accuracy of ' + model_names[count] + ' is ' + str(cv_score.mean()))\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7J-23z78i0Ns"
      },
      "source": [
        "###3.4 Use Grid Search to Find Optimal Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hpe9PEAAi0Nt",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# helper function for printing out grid search results \n",
        "def print_grid_search_metrics(gs):\n",
        "    print (\"Best score: \" + str(gs.best_score_))\n",
        "    print (\"Best parameters set:\")\n",
        "    best_parameters = gs.best_params_\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(param_name + ':' + str(best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qvYo9I5Ti0Nv"
      },
      "source": [
        "####3.4.1 Find Optimal Hyperparameters - LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOc48syxi0Nx",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Possible hyperparamter options for Logistic Regression Regularization\n",
        "# Penalty is choosed from L1 or L2\n",
        "# C is the lambda value(weight) for L1 and L2\n",
        "\n",
        "# ('l1', 1) ('l1', 5) ('l1', 10) ('l2', 1) ('l2', 5) ('l2', 10)\n",
        "parameters = {\n",
        "    'penalty':('l1', 'l2'), \n",
        "    'C':(0.01, 0.1, 1, 5, 10)\n",
        "}\n",
        "Grid_LR = GridSearchCV(LogisticRegression(solver='liblinear'),parameters, cv=5)\n",
        "Grid_LR.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nN5rU0e-i0N1",
        "colab": {}
      },
      "source": [
        "# the best hyperparameter combination\n",
        "print_grid_search_metrics(Grid_LR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TtkDsXgui0N3",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "best_LR_model = Grid_LR.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9u9YFedOi0N6"
      },
      "source": [
        "####3.4.2 Find Optimal Hyperparameters: KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o78422XVi0N6",
        "colab": {}
      },
      "source": [
        "# Possible hyperparamter options for KNN\n",
        "# Choose k\n",
        "parameters = {\n",
        "    'n_neighbors':[1,3,5,7,9] \n",
        "}\n",
        "Grid_KNN = GridSearchCV(KNeighborsClassifier(),parameters, cv=5)\n",
        "Grid_KNN.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydaRZVAIi0N_",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# best k\n",
        "print_grid_search_metrics(Grid_KNN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq_qfVpXUJcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_KNN_model = Grid_KNN.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nKn_oKLSi0OB"
      },
      "source": [
        "####3.4.3 Find Optimal Hyperparameters: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NniAZIPfi0OC",
        "colab": {}
      },
      "source": [
        "# Possible hyperparamter options for Random Forest\n",
        "# Choose the number of trees\n",
        "parameters = {\n",
        "    'n_estimators' : [40,60,80]\n",
        "}\n",
        "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
        "Grid_RF.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScPiI-Bfi0OE",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# best number of tress\n",
        "print_grid_search_metrics(Grid_RF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xJgfri_Mi0OG",
        "colab": {}
      },
      "source": [
        "# best random forest\n",
        "best_RF_model = Grid_RF.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiQEPfWjX1Xr",
        "colab_type": "text"
      },
      "source": [
        "####3.4.4 Find Optimal Hyperparameters: Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQUCoEyMX80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Possible hyperparamter options for SVM\n",
        "# Choose kernal \n",
        "parameters = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]}\n",
        "Grid_SVM = GridSearchCV(svm.SVC(),parameters, cv=5)\n",
        "Grid_SVM.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6HXcDKjmEGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best gmma and C\n",
        "print_grid_search_metrics(Grid_SVM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Zv4IpwmLyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best SVM model\n",
        "best_SVM_model = Grid_SVM.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xxDAOrGIi0OI"
      },
      "source": [
        "###3.5 Model Evaluation \n",
        "\n",
        "class of interest as positive\n",
        "\n",
        "TP: correctly labeled real churn\n",
        "\n",
        "Precision(PPV, positive predictive value): tp / (tp + fp);\n",
        "Total number of true predictive churn divided by the total number of predictive churn;\n",
        "High Precision means low fp, not many return users were predicted as churn users. \n",
        "\n",
        "\n",
        "Recall(sensitivity, hit rate, true positive rate): tp / (tp + fn)\n",
        "Predict most postive or churn user correctly. High recall means low fn, not many churn users were predicted as return users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFpfODYUbBZR",
        "colab_type": "text"
      },
      "source": [
        "####3.5.1 Model Evaluation - Confusion Matrix (Precision, Recall, Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-tP94iFi0OI",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
        "def cal_evaluation(classifier, cm):\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "    precision = tp / (tp + fp + 0.0)\n",
        "    recall = tp / (tp + fn + 0.0)\n",
        "    print (classifier)\n",
        "    print (\"Accuracy is: \" + str(accuracy))\n",
        "    print (\"precision is: \" + str(precision))\n",
        "    print (\"recall is: \" + str(recall))\n",
        "\n",
        "# print out confusion matrices\n",
        "def draw_confusion_matrices(confusion_matricies):\n",
        "    class_names = ['Retain','Churn']\n",
        "    for cm in confusion_matrices:\n",
        "        classifier, cm = cm[0], cm[1]\n",
        "        cal_evaluation(classifier, cm)\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
        "        plt.title('Confusion matrix for ' + classifier)\n",
        "        fig.colorbar(cax)\n",
        "        ax.set_xticklabels([''] + class_names)\n",
        "        ax.set_yticklabels([''] + class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUeBJVDYmr9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#confusion_matrix(y_test,best_RF_model.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OpSGaN49i0OL",
        "colab": {}
      },
      "source": [
        "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
        "confusion_matrices = [\n",
        "    (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test))),\n",
        "    (\"Logistic Regression\", confusion_matrix(y_test,best_LR_model.predict(X_test))),\n",
        "    (\"K nearest neighbor\", confusion_matrix(y_test, best_KNN_model.predict(X_test))),\n",
        "    ('Support Vector Moachines', confusion_matrix(y_test, best_SVM_model.predict(X_test)))\n",
        "]\n",
        "\n",
        "draw_confusion_matrices(confusion_matrices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us7d3hy4nMFU",
        "colab_type": "text"
      },
      "source": [
        "Random Forest has the best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OvHlyhPBi0OT"
      },
      "source": [
        "#### 3.5.2 Model Evaluation - ROC & AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Os_ZLTvi0OX"
      },
      "source": [
        "ROC of RF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UypvQMVBi0OY",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "# Use predict_proba to get the probability results of Random Forest\n",
        "y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s3PR-PdPi0Ob",
        "colab": {}
      },
      "source": [
        "# ROC curve of Random Forest result\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - RF model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R89IUMYDi0Oe",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# AUC score\n",
        "metrics.auc(fpr_rf,tpr_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-1DVqnJVi0Oh"
      },
      "source": [
        "ROC of LR Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-q5XJPoi0Oi",
        "colab": {}
      },
      "source": [
        "# Use predict_proba to get the probability results of Logistic Regression\n",
        "y_pred_lr = best_LR_model.predict_proba(X_test)[:, 1]\n",
        "fpr_lr, tpr_lr, thres = roc_curve(y_test, y_pred_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZSrN-1Mi0Ok",
        "colab": {}
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - LR Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LHAyxishi0On",
        "colab": {}
      },
      "source": [
        "# AUC score\n",
        "metrics.auc(fpr_lr,tpr_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el9bfdL3pv-U",
        "colab_type": "text"
      },
      "source": [
        "ROC of KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5tB2DE1pzBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_knn = best_KNN_model.predict(X_test)\n",
        "fpr_knn, tpr_knn, thres = roc_curve(y_test, y_pred_knn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXZfeI_Op3Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_knn, tpr_knn, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - KNN Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qb06U-8qGAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.auc(fpr_knn, tpr_knn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMfOR9hTobZi",
        "colab_type": "text"
      },
      "source": [
        "ROC of SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm6WYE3Ro0eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_svm = best_SVM_model.predict(X_test)\n",
        "fpr_svm, tpr_svm, thres = roc_curve(y_test, y_pred_svm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfAA4FajpUbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_svm, tpr_svm, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - SVM Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8-8buwSpbzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.auc(fpr_svm, tpr_svm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHHurD8Ii0Oq"
      },
      "source": [
        "# Part 4: Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dSx4TPO-i0Or"
      },
      "source": [
        "###4.1 Logistic Regression Model - Feature Selection Discussion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BtLHUixoi0Ot"
      },
      "source": [
        "The corelated features that we are interested in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQaXOIsUi0Ou",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# add L1 regularization to logistic regression\n",
        "# check the coef for feature selection\n",
        "scaler = StandardScaler()\n",
        "X_l1 = scaler.fit_transform(X)\n",
        "LRmodel_l1 = LogisticRegression(penalty=\"l1\", C = 0.01, solver='liblinear')\n",
        "LRmodel_l1.fit(X_l1, y)\n",
        "\n",
        "indices = np.argsort(abs(LRmodel_l1.coef_[0]))[::-1]\n",
        "\n",
        "print (\"Logistic Regression (L1) Coefficients\")\n",
        "for ind in range(X.shape[1]):\n",
        "  print (\"{0} : {1}\".format(X.columns[indices[ind]],round(LRmodel_l1.coef_[0][indices[ind]], 4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_qOdN4Nr7sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = X_train.columns.values\n",
        "importances_l1 = abs(LRmodel_l1.coef_[0])\n",
        "plt.figure(1)\n",
        "axes = plt.gca()\n",
        "plt.bar(feature_name[indices], importances_l1[indices])\n",
        "plt.title('feature importance of L1 model')\n",
        "plt.xticks(rotation=90)\n",
        "#axes.set_ylim([-0.2,0.5])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "majifZZqi0O9",
        "colab": {}
      },
      "source": [
        "# add L2 regularization to logistic regression\n",
        "# check the coef for feature selection\n",
        "np.random.seed()\n",
        "scaler = StandardScaler()\n",
        "X_l2 = scaler.fit_transform(X)\n",
        "LRmodel_l2 = LogisticRegression(penalty=\"l2\", C = 0.1, solver='liblinear', random_state=42)\n",
        "LRmodel_l2.fit(X_l2, y)\n",
        "LRmodel_l2.coef_[0]\n",
        "\n",
        "indices = np.argsort(abs(LRmodel_l2.coef_[0]))[::-1]\n",
        "\n",
        "print (\"Logistic Regression (L2) Coefficients\")\n",
        "for ind in range(X.shape[1]):\n",
        "  print (\"{0} : {1}\".format(X.columns[indices[ind]],round(LRmodel_l2.coef_[0][indices[ind]], 4)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jvxBT8prPu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = X_train.columns.values\n",
        "plt.figure(1)\n",
        "importances_l2 = abs(LRmodel_l2.coef_[0])\n",
        "axes = plt.gca()\n",
        "plt.bar(feature_name[indices], importances_l2[indices])\n",
        "plt.title('feature importance of L2 model')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqs41ydLi0O_"
      },
      "source": [
        "###4.2 Random Forest Model - Feature Importance Discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MPxUM2lei0PA",
        "colab": {}
      },
      "source": [
        "# check feature importance of random forest for feature selection\n",
        "forest = RandomForestClassifier()\n",
        "forest.fit(X, y)\n",
        "\n",
        "importances = forest.feature_importances_\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature importance ranking by Random Forest Model:\")\n",
        "for ind in range(X.shape[1]):\n",
        "  print (\"{0} : {1}\".format(X.columns[indices[ind]],round(importances[indices[ind]], 4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACL0d-4gq8cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_name = X_train.columns.values\n",
        "plt.figure(1)\n",
        "plt.bar(feature_name[indices], importances[indices])\n",
        "plt.title('feature importance of Random Forest model')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}